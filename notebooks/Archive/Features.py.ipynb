{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import zipcodes\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import pathlib\n",
    "import sys\n",
    "sys.path.append(str(pathlib.Path().absolute().parent))\n",
    "\n",
    "\n",
    "\n",
    "# LOAD DATA\n",
    "city_ts = pd.read_csv('../data/raw/unzipped/City_time_series.csv')\n",
    "zip_ts = pd.read_csv('../data/raw/unzipped/Zip_time_series.csv')\n",
    "\n",
    "fips_mapping = pd.read_pickle('../data/interim/fips_map.pickle')\n",
    "\n",
    "\n",
    "# PARE DOWN CITY TABLE TO JUST CA\n",
    "city_ts_merged = city_ts.merge(fips_mapping,\n",
    "                              how='left',\n",
    "                              left_on='RegionName',\n",
    "                              right_on='Unique_City_ID')\n",
    "\n",
    "ca_city_ts = city_ts_merged[city_ts_merged['State'] == 'CA']\n",
    "ca_city_ts.rename(columns={'RegionName_x': 'RegionName'}, inplace=True)\n",
    "ca_city_ts.drop('RegionName_y', axis=1, inplace=True)\n",
    "ca_city_ts.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Free up memory\n",
    "del city_ts_merged\n",
    "del city_ts\n",
    "\n",
    "\n",
    "# PARE DOWN ZIP TABLE TO JUST CA \n",
    "## Note: All CA Zipcodes start with the number 9\n",
    "zip_ts['ZipCode_str'] = zip_ts['RegionName'].astype(str)\n",
    "maybe_ca_zips = [zipcode for zipcode in zip_ts['ZipCode_str'].unique().tolist() if zipcode[0] == '9']\n",
    "\n",
    "# Use `zipcodes` to pare down the maybe_ca_zips to DEFINITE CA zips\n",
    "confirmed_CA_zips = []\n",
    "\n",
    "for zipcode in maybe_ca_zips:\n",
    "    zip_info = zipcodes.matching(zipcode)[0]\n",
    "    if zip_info['state'] == 'CA':\n",
    "        confirmed_CA_zips.append(zipcode)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "ca_zip_ts = zip_ts[zip_ts['ZipCode_str'].isin(confirmed_CA_zips)]\n",
    "ca_zip_ts.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Expand the ca_zip_ts table to include additional location metadata like lat/long/city/county etc.\n",
    "zip_city_map = dict()\n",
    "zip_county_map = dict()\n",
    "zip_latlong = dict()\n",
    "\n",
    "for zipcode in ca_zip_ts['ZipCode_str'].unique():\n",
    "    zipinfo = zipcodes.matching(zipcode)\n",
    "    try: \n",
    "        for info in zipinfo:\n",
    "            zip_city_map[zipcode] = info['city']\n",
    "            zip_county_map[zipcode] = info['county']\n",
    "            zip_latlong[zipcode] = {'Lat' : info['lat'], 'Long' : info['long']}\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "ca_zip_ts['City'] = [zip_city_map[row.ZipCode_str] for row in ca_zip_ts.itertuples()]\n",
    "ca_zip_ts['County'] = [zip_county_map[row.ZipCode_str] for row in ca_zip_ts.itertuples()]\n",
    "ca_zip_ts['Lat'] = [zip_latlong[row.ZipCode_str]['Lat'] for row in ca_zip_ts.itertuples()]\n",
    "ca_zip_ts['Long'] = [zip_latlong[row.ZipCode_str]['Long'] for row in ca_zip_ts.itertuples()]\n",
    "\n",
    "\n",
    "# Intermediate Step: Pare down FIPS Mapping to only CA and then grab zipcodes using `zipcodes` package\n",
    "fips_mapping_CA = fips_mapping.loc[fips_mapping['State'] == 'CA']\n",
    "fips_mapping_CA.reset_index(drop=True, inplace=True)\n",
    "\n",
    "zip_meta = dict()\n",
    "for row in fips_mapping_CA.itertuples():\n",
    "    city_to_check = row.City\n",
    "    info = zipcodes.filter_by(city=city_to_check)\n",
    "    for i in info:\n",
    "        if row.County in i['county']:\n",
    "            zip_meta[i['zip_code']] = {'Lat': float(i['lat']), \n",
    "                                          'Long': float(i['long']),\n",
    "                                          'City' : i['city'],\n",
    "                                          'County' : i['county'].replace(\" County\", \"\")}\n",
    "# Convert the dict to DataFrame\n",
    "zip_meta_df = pd.DataFrame(zip_meta).T\n",
    "zip_meta_df.reset_index(inplace=True)\n",
    "\n",
    "city_uniqueCityID = dict(zip(fips_mapping_CA['City'], fips_mapping_CA['Unique_City_ID']))\n",
    "city_metroName = dict(zip(fips_mapping_CA['City'], fips_mapping_CA['MetroName']))\n",
    "city_regionName = dict(zip(fips_mapping_CA['City'], fips_mapping_CA['RegionName']))\n",
    " \n",
    "zip_meta_df['State'] = 'CA'\n",
    "zip_meta_df['StateName'] = 'California'\n",
    "zip_meta_df['CensusRegion'] = 'West'\n",
    "\n",
    "metroname_column = list()\n",
    "uniquecityID_column = list()\n",
    "regionname_column = list()\n",
    "\n",
    "for city in zip_meta_df['City']:\n",
    "    if city in city_uniqueCityID and city in city_metroName:\n",
    "        uniquecityID_column.append(city_uniqueCityID[city])\n",
    "        metroname_column.append(city_metroName[city])\n",
    "        regionname_column.append(city_regionName[city])\n",
    "    else:\n",
    "        uniquecityID_column.append(np.nan)\n",
    "        metroname_column.append(np.nan)\n",
    "        regionname_column.append(np.nan)\n",
    "        \n",
    "zip_meta_df['Unique_City_ID'] = uniquecityID_column\n",
    "zip_meta_df['MetroName'] = metroname_column\n",
    "zip_meta_df['RegionName'] = regionname_column\n",
    "\n",
    "zip_meta_df.rename(columns={'index':'ZipCode'}, inplace=True)\n",
    "\n",
    "fips_zip_mapping_CA = zip_meta_df.copy()\n",
    "\n",
    "# Free up memory\n",
    "del fips_mapping\n",
    "del zip_meta_df\n",
    "\n",
    "# Pare down the data to only hone in in the ZHVI and ZRI columns (which are the most complete of all avail info)\n",
    "ZHVI_ZRI_columns = ['ZHVIPerSqft_AllHomes', 'PctOfHomesDecreasingInValues_AllHomes',\n",
    "       'PctOfHomesIncreasingInValues_AllHomes',\n",
    "       'PctOfListingsWithPriceReductionsSeasAdj_AllHomes',\n",
    "       'PctOfListingsWithPriceReductionsSeasAdj_CondoCoop',\n",
    "       'PctOfListingsWithPriceReductionsSeasAdj_SingleFamilyResidence',\n",
    "       'PctOfListingsWithPriceReductions_AllHomes',\n",
    "       'PctOfListingsWithPriceReductions_CondoCoop',\n",
    "       'PctOfListingsWithPriceReductions_SingleFamilyResidence',\n",
    "       'PriceToRentRatio_AllHomes', 'ZHVI_1bedroom', 'ZHVI_2bedroom',\n",
    "       'ZHVI_3bedroom', 'ZHVI_4bedroom', 'ZHVI_5BedroomOrMore',\n",
    "       'ZHVI_AllHomes', 'ZHVI_BottomTier', 'ZHVI_CondoCoop', 'ZHVI_MiddleTier',\n",
    "       'ZHVI_SingleFamilyResidence', 'ZHVI_TopTier', 'ZRI_AllHomes',\n",
    "       'ZRI_AllHomesPlusMultifamily', 'ZriPerSqft_AllHomes',\n",
    "       'Zri_MultiFamilyResidenceRental', 'Zri_SingleFamilyResidenceRental']\n",
    "\n",
    "fips_loc_columns = ['ZipCode_str', 'City', 'County', 'Lat', 'Long']\n",
    "\n",
    "city_ts_columns = ['Date', 'MetroName', 'StateName', 'CensusRegion', 'Unique_City_ID', 'City', 'County', 'State']\n",
    "zip_ts_columns = ['Date', 'RegionName', 'ZipCode_str', 'City', 'County', 'Lat', 'Long']\n",
    "\n",
    "ca_city_zill_ts = ca_city_ts[city_ts_columns + ZHVI_ZRI_columns]\n",
    "ca_zip_zill_ts = ca_zip_ts[zip_ts_columns + ZHVI_ZRI_columns]\n",
    "\n",
    "# EXPAND THE CITY DATA WITH ZIP INFORMATION \n",
    "# Use the updated fips_zip_mapping_df to expand the location metadata is in both the city and the zip tables\n",
    "city_w_zips_ts = ca_city_zill_ts.merge(fips_zip_mapping_CA,\n",
    "                                     on='Unique_City_ID',\n",
    "                                     how='left',\n",
    "                                     suffixes=('', '_y'))\n",
    "\n",
    "# Remove duplicate columns as a result of the merge\n",
    "for col in city_w_zips_ts.columns:\n",
    "    if '_y' in col:\n",
    "        city_w_zips_ts.drop(col, axis=1, inplace=True)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# Remove the rows with Zipcodes already in the Zip TS table\n",
    "city_w_zips_ts = city_w_zips_ts[~city_w_zips_ts['ZipCode'].isin(list(set(ca_zip_zill_ts['ZipCode_str'])))]  \n",
    "city_w_zips_ts.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# EXPAND THE ZIP DATA WITH CITY INFORMATION\n",
    "ca_zip_zill_ts.rename(columns={'RegionName':'ZipCode_int'}, inplace=True)\n",
    "ca_zip_zill_ts['County'] = [countyname.replace(\" County\", \"\") if \" County\" in countyname else countyname \n",
    "                            for countyname in ca_zip_zill_ts['County']]\n",
    "\n",
    "ca_zip_w_fips = ca_zip_zill_ts.merge(fips_mapping_CA,\n",
    "                                     how='left',\n",
    "                                     on=['City', 'County'])\n",
    "\n",
    "\n",
    "# Save the files (prior to imputing with city-data): \n",
    "ca_city_ts.to_pickle('../data/interim/california-city-ts.pickle')\n",
    "ca_zip_ts.to_pickle('../data/interim/california-zip-ts.pickle')\n",
    "\n",
    "# Save the files (after imputing missing zipcodes with city data)\n",
    "city_w_zips_ts.to_pickle('../data/interim/ca-city-w-zip-ts.pickle')\n",
    "ca_zip_w_fips.to_pickle('../data/interim/ca-zip-w-city-ts.pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ba98b80eb4c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# the column we wish teo forecast must be labeled 'y'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mPrep_For_Modeling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-ba98b80eb4c4>\u001b[0m in \u001b[0;36mPrep_For_Modeling\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0muser_specified_zipCode\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzipcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         '''\n\u001b[1;32m     34\u001b[0m         \u001b[0mpare\u001b[0m \u001b[0mdown\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mto\u001b[0m \u001b[0monly\u001b[0m \u001b[0mrelevant\u001b[0m \u001b[0mzipcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "# Load Data from data/interim directory:\n",
    "zip_w_city = pd.read_pickle('../data/interim/ca-zip-w-city-ts.pickle')\n",
    "city_w_zip = pd.read_pickle('../data/interim/ca-city-w-zip-ts.pickle')\n",
    "\n",
    "ts_data = pd.concat([zip_w_city, city_w_zip])\n",
    "\n",
    "# Transformations necessary for FB Prophet\n",
    "# the date column must be a datetime type and labeled 'ds'\n",
    "# the column we wish teo forecast must be labeled 'y'\n",
    "\n",
    "class Prep_For_Modeling():\n",
    "\n",
    "    def __init__(self, ts_df):     \n",
    "        '''\n",
    "        When initializing, pass in the time series DataFrame\n",
    "        '''\n",
    "        self.ts = ts_df\n",
    "        self.zip = pd.DataFrame\n",
    "        self.br = pd.DataFrame\n",
    "        \n",
    "\n",
    "    def convert_str_date_to_datetime (self, df:pd.DataFrame=ts_data) -> pd.DataFrame:\n",
    "        '''\n",
    "        converts the string values in \"Date\" column to datetime objects\n",
    "        renames the \"Date\" column to \"ds\n",
    "        '''\n",
    "        assert 'Date' in df.columns, 'df columns must contain a column \"Date\".'\n",
    "        df['ds'] = df['Date'].apply(lambda _ : datetime.strptime(_, \"%Y-%m-%d\"))\n",
    "        return df.drop('Date', axis=1)\n",
    "\n",
    "\n",
    "    def user_specified_zipCode (self, zipcode, df:pd.DataFrame=self.ts) -> pd.DataFrame:\n",
    "        '''\n",
    "        pare down training data to only relevant zipcode\n",
    "        '''\n",
    "        if type(zipcode) == str: \n",
    "            pass\n",
    "        elif type(zipcode) == float or type(zipcode) == int:\n",
    "            zipcode = str(zipcode)\n",
    "\n",
    "        zip_ts = df[df['ZipCode'] == zipcode]\n",
    "        zip_ts.reset_index(drop=True, inplace=True)\n",
    "        self.zip = zip_ts\n",
    "        \n",
    "\n",
    "    def user_specified_BR (self, num_of_br, df:pd.DataFrame=self.zip) -> pd.DataFrame:\n",
    "        '''\n",
    "        pare down training data to only relevant columns\n",
    "        '''\n",
    "        if type(num_of_br) == str:\n",
    "            pass\n",
    "        elif type(num_of_br) == float or type(num_of_br) == int:\n",
    "            num_of_br = str(num_of_br)\n",
    "\n",
    "        cols_to_get = [col for col in df.columns if num_of_br in col]\n",
    "        self.br = df[cols_to_get]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
